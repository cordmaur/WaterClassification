# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

# __all__ = ['s2bands', 's2bands_norm', 'save_obj', 'load_obj', 'wavelength_range', 'calc_area', 'normalize',
#            'apply_subplot', 'fig_to_html', 'showfig', 'log_color_scatter', 'plot_reflectances',
#            'plot_mean_reflectances', 'plot_ids', 'series_to_annotation', 'cluster_and_plot_scatter',
#            'multi_cluster_and_plot', 'PCA_decomposition', 'clusterize', 'calc_df_grouped_stats', 'nir_red_ratio',
#            'linear', 'expo', 'power', 'poly', 'nechad', 'fit_curve', 'calc_errors', 'plot_data_and_curve',
#            'fit_and_plot_curve']

# Cell
import io
import plotly
import plotly.io as pio
import plotly.express as px
import plotly.graph_objects as go
import matplotlib

from PIL import Image

import pickle

import pandas as pd
import numpy as np
import math

from sklearn import decomposition, cluster

from IPython.core.display import display, HTML

# Cell
s2bands = ['443', '490', '560', '665', '705', '740', '783', '842', '865', '940']
s2bands_norm = [f'n{b}' for b in s2bands]

# S3 bands
s3bands = ['400', '412', '442', '490', '510', '560', '620', '665', '674', '681', '709', '754', '761', '764',
           '767', '779', '865', '885', '900', '940']
s3bands_norm = [f'n{b}' for b in s3bands]


def wavelength_range(ini_wl, last_wl, step=1, prefix=''):
    """Creates a range of wavelengths from initial to last, in a defined nanometers step."""
    return [f'{prefix}{wl}' for wl in range(ini_wl, last_wl + 1, step)]


all_wls = wavelength_range(380, 920)
all_wls_norm = [f'n{b}' for b in all_wls]


def listify(*args):
    result = []
    for arg in args:
        result.append(arg if isinstance(arg, slice) or isinstance(arg, list) else ([] if arg is None else [arg]))
    if len(result) == 1:
        return result[0]
    else:
        return tuple(result)


# ------------------- INTERPOLATION ------------------
def convert_columns_titles_types(df, data_type=float):
    """Change the columns titles names to a numerical format to interpolate the values accordingly"""
    for column in df.columns:
        try:
            new_name = data_type(column)

            if data_type is not str:
                frac, _ = math.modf(new_name)
                if frac == 0:
                    new_name = int(new_name)

            df = df.rename(columns={column: new_name})

        except:
            pass

    return df


def sort_numerical_columns_titles(df):
    """Order the numerical columns titles in ascending order. Will consider numerical,
    all the columns whose titles are not strings"""
    str_columns = [column for column in df.columns if isinstance(column, str)]
    num_columns = [column for column in df.columns if not isinstance(column, str)]
    num_columns.sort()
    return df[str_columns + num_columns]


def sort_column_titles(df):
    new_df = convert_columns_titles_types(df, float)
    new_df = sort_numerical_columns_titles(new_df)
    new_df = convert_columns_titles_types(new_df, str)
    return new_df


def create_evenly_spaced_columns(df, step=1, dtype=int, min_col=320, max_col=950):
    num_columns = [column for column in df.columns if not isinstance(column, str)]
    num_columns.sort()

    min_column = num_columns[0] if min_col is None else min_col
    max_column = num_columns[-1] if max_col is None else max_col

    start = math.ceil(min_column)
    end = math.floor(max_column)

    new_columns = np.arange(start, end, step, dtype=dtype)
    # clean the new columns, with existent numerical columns
    new_columns = [c for c in new_columns if c not in num_columns]

    df[new_columns] = pd.DataFrame([[np.nan for _ in new_columns]], index=df.index)
    return list(new_columns)


def create_interpolated_columns(df, step=1, drop_original_columns=True, create_id=True, min_col=None, max_col=None):
    """Create evenly spaced columns (wavelengths), according to a given step and interpolate the values linearly"""
    df = convert_columns_titles_types(df)
    new_columns = create_evenly_spaced_columns(df, step=step, dtype=type(step), min_col=min_col, max_col=max_col)

    # get the numerical and the string columns to treat them separately
    num_columns = [column for column in df.columns if not isinstance(column, str)]
    str_columns = [column for column in df.columns if isinstance(column, str)]
    num_columns.sort()

    # convert all the values to float32 format
    for column in num_columns:
        df[column] = pd.to_numeric(df[column], errors='coerce', downcast='float')

    # proceed the interpolation
    df.loc[:, num_columns] = df[num_columns].astype('float').interpolate(method='index',
                                                                         axis=1,
                                                                         limit_area='inside')

    columns = new_columns if drop_original_columns else num_columns
    df = df[str_columns + columns]

    if create_id:
        df = df.reset_index().rename(columns={'index': 'Id'})

    # convert the columns titles back to strings
    convert_columns_titles_types(df, data_type=str)
    return df


def save_obj(obj, name):
    with open(str(name), 'wb') as f:
        pickle.dump(obj, f)


def load_obj(name):
    with open(str(name), 'rb') as f:
        result = pickle.load(f)
    return result


def wavelength_range(ini_wl, last_wl, step=1, prefix=''):
    "Creates a range of wavelengths from initial to last, in a defined nanometers step."
    return [f'{prefix}{wl}' for wl in range(ini_wl, last_wl+1, step)]


def calc_area(df, bands=None, col_name="area", norm_band=None):
    """Calc the integral of the curve and adds it to a new column.
    norm_band: the normalization band reflectance will be used to subtract the curve
    """
    bands = df.columns[df.columns.str.isdigit()] if bands is None else bands

    values = df.fillna(0)[bands].to_numpy()

    if norm_band is not None:
        norm_vector = df.fillna(0)[norm_band].to_numpy()
        values = values - norm_vector[..., None]

    df[col_name] = np.trapz(values)
    return df


def normalize(df, bands=None, inplace=False, add_columns=False):
    """Normalize the reflectance spectra by dividing all reflectance values by the area under the curve.
    All normalized spectra will have area=1.
    add_columns will add the normalized columns to the data frame"""

    bands = df.columns[df.columns.str.isdigit()] if bands is None else bands

    if 'area' not in df.columns:
        calc_area(df, bands)

    df_norm = df if inplace else df.copy()

    # if add_columns, we will append new columns to the dataframe (inplace or new dataframe)
    new_bands = [f'n{b}' for b in bands] if add_columns else bands

    df_norm[new_bands] = df[bands]/df.area.to_numpy()[..., None]

    return df_norm


def fig_to_html(fig, buttonsToRemove=[], **kwargs):
    "Converts a plotly figure into a HTML graph and displays it. That is necessary to maintain the interactive functionality of plotly in the jekyll documentation, on Github."

    html = io.StringIO()
    buttonsToRemove += ['toggleSpikelines', 'hoverCompareCartesian', 'zoomIn2d',
                        'zoomOut2d', 'autoScale2d', 'hoverClosestCartesian']
    pio.write_html(fig, file=html, auto_open=False,
                   config={'modeBarButtonsToRemove': buttonsToRemove,
                           'displaylogo': False,
                          }
                  )

    display(HTML(data=html.getvalue()))


def showfig(fig, publish_mode='fig', **kwargs):
    if publish_mode == 'html':
        fig_to_html(fig, **kwargs)

    elif publish_mode == 'png':
        png = io.BytesIO()
        pio.write_image(fig, file=png, **kwargs)

        return Image.open(png)
    else:
        return fig


def log_color_scatter(*args, **kwargs):
    "Proxy for px.scatter applying log to the color scale."

    kwargs['color'] = np.log10(kwargs['color'])

    fig = px.scatter(*args, **kwargs)

    # take care of the logarithmic colors and labels
    fig.update_traces(marker=dict(size=4))
    tickvals=np.array([0, 0.5, 1, 1.5, 2, 2.5, 3])
    ticktext=np.power(10, tickvals)
    ticktext = list(map(lambda x: round(x), ticktext.tolist()))
    fig.update_layout(coloraxis_colorbar=dict(title="SPM", tickvals=tickvals, ticktext=ticktext))
    # showfig(fig)
    return fig


def apply_subplot(fig, subplot, position):
    for t in subplot.data:
        # check if there is a color_bar to ajust its size
        if t.marker.colorbar.len:
            # get the y_axis domain for this specific subplot
            y_domain = fig.get_subplot(position[0], position[1]).yaxis.domain

            # adjust the colorbar accordingly
            t.marker.colorbar.len = y_domain[1] - y_domain[0]
            t.marker.colorbar.y = (y_domain[1] + y_domain[0]) / 2

        fig.add_trace(t, row=position[0], col=position[1])

    for axis, update_ax_func in zip(['xaxis', 'yaxis'], [fig.update_xaxes, fig.update_yaxes]):
        update_dic = {}
        for param in ['title', 'type']:
            update_dic.update({param: subplot.layout[axis][param]})
        update_ax_func(update_dic, row=position[0], col=position[1])

    return fig


def plot_figures(rows, cols, figs: list, base_height=400, titles=None):
    fig = plotly.subplots.make_subplots(rows=rows, cols=cols, subplot_titles=titles)

    for i, subplot in enumerate(figs):
        row = i // cols + 1
        col = i % cols + 1

        apply_subplot(fig, subplot, (row, col))

    fig.update_layout(showlegend=False, height=base_height * rows)
    return fig


def plot_reflectances(df, id_vars=['Id'], Key='Id', color='Id', bands=s2bands, title=''):
    melted_df = pd.melt(df.reset_index(), id_vars=id_vars, value_vars=bands)

    return px.line(melted_df, x='variable', y='value', color=color, line_group=Key, hover_data=id_vars, title=title,
                   render_mode='svg')


def plot_mean_reflectances(df, group_by, id_vars=['Id'], color='Id', bands=s2bands, title=''):
    mean_df = df.groupby(by=group_by).mean().reset_index()

    return plot_reflectances(mean_df, id_vars=id_vars, Key=group_by, color=group_by, bands=bands, title=title)


def plot_ids(df, ids, id_vars=['Id', 'SPM', 'Status', 'Area', 'Start_Date', 'Station', 'Project'], Key='Id', color='Id',
             bands=s2bands, title=''):
    sub_df = df.loc[ids]

    return plot_reflectances(sub_df, id_vars, Key, color, bands, title)


def plot_reflectances2(df, bands, color='SPM', hover_vars=['SPM', 'Area'], colormap='viridis', log_color=True,
                       colorbar=True, show_legend=False):

    if color:
        min = df[color][df[color] > 0].min()
        max = df[color].max()

        cmap = matplotlib.cm.get_cmap(colormap)
        norm = matplotlib.colors.LogNorm(min, max) if log_color else matplotlib.colors.Normalize(min, max)

    scatters = []
    for idx in df.index:
        row = df.loc[idx]
        reflectances = row[bands]
        x = reflectances.index
        y = reflectances.values

        color_value = f'rgb{cmap(norm(row[color]))[:3]}' if color else 'grey'

        hover_text = ''
        for var in hover_vars:
            hover_text += f'{var}: {row[var]}<br>'

        scatters.append(go.Scatter(x=x.astype('float'), y=y,
                                   text=hover_text,
                                   name=idx,
                                   line=dict(width=0.5,
                                   color=color_value),
                                   showlegend=show_legend
                                   ))

    fig = go.Figure(data=scatters)

    # create the colorbar
    if colorbar and color:
        colorbar_trace = go.Scatter(x=[None],
                                    y=[None],
                                    mode='markers',
                                    marker=dict(
                                        colorscale=colormap,
                                        showscale=True,
                                        cmin=min,
                                        cmax=max,
                                        colorbar=dict(xanchor="left", title='', thickness=30,
                                                      tickvals=[min, (min + max) / 2, max],
                                                      ticktext=[min, (min + max) / 2, max],
                                                      len=1, y=0.5
                                                      ),
                                    ),
                                    hoverinfo='none'
                                    )

        fig.add_trace(colorbar_trace)

    fig.update_layout(
        showlegend=True,
        title="Measurements (full spectra)",
        xaxis_title="Wavelength (nm)",
        yaxis_title="Reflectance - Rrs (sr^-1)",
        font=dict(
            family="Courier New, monospace",
            size=12,
            color="RebeccaPurple"))

    return fig


def plot_grouped_reflectances(df, group='Rio/ Bacia', bands=s2bands, color='SPM',
                              hover_vars=['SPM', 'Rio/ Bacia'], colormap='viridis', log_color=True,
                              base_height=400
                              ):
    # create a plotly figure with the correct number of lines
    groups = df[group].unique()
    fig = plotly.subplots.make_subplots(rows=len(groups), cols=1,
                                        subplot_titles=[f'{group}: {g}' for g in groups])

    # loop through the groups
    for i, g in enumerate(groups):
        subdf = df[df[group] == g]
        subplot = plot_reflectances2(subdf, bands=bands, hover_vars=hover_vars,
                                     colormap=colormap, color=color, log_color=log_color)
        apply_subplot(fig, subplot, (i + 1, 1))

    fig.update_layout(showlegend=False, height=base_height * len(groups))

    return fig


def series_to_annotation(s):
    "create a formatted annotation string given the series"
    res = ""
    for name, value in s.items():
        res += f'{name}: {round(value,2)} <br>'

    return res


from collections.abc import Iterable


def cluster_and_plot_scatter(df, bands, clusters, x, y, color, continuous=True, hover_name=None, labels=None, title='cluster', log_y=False, height=300, marker_size=4):
    "Do the clustering and plot a scatter with the informed axes."
    # do the clusterring
    cl_df = clusterize(df, bands, n_clusters=clusters)

    if not continuous: color = cl_df[color].astype('str')

    # plot the scatter into a figure
    fig = px.scatter(cl_df, x=x, y=y, color=color, hover_name=cl_df.index, height=height,
                     labels=labels, log_y=log_y
                    )
    fig.update_traces(marker=dict(size=marker_size))

    return fig


def multi_cluster_and_plot(dfs, bands, clusters_range, x, y, color, continuous=True, hover_name=None, labels=None, title='cluster', log_y=False, log_x=False,
                           height=300, marker_size=4, dfs_names=None):
    "Creates a grid of len(dfs) rows and len(clusters_range) columns to compare different clustering results"

    # Convert dfs and clusters_range to list, so it does not raise expception
    dfs = [dfs] if not isinstance(dfs, list) else dfs
    clusters_range = [clusters_range] if not isinstance(clusters_range, Iterable) else clusters_range

    cols = len(dfs)
    rows = len(clusters_range)

    col_names = dfs_names if dfs_names is not None else range(len(dfs))

    titles = []
    for row in clusters_range:
        for col in col_names:
            titles.append(f'{col}  (clusters={row})')

    fig = plotly.subplots.make_subplots(rows=rows, cols=cols, subplot_titles=titles)

    for row, clusters in enumerate(clusters_range):
        for col, df in enumerate(dfs):
            subfig = cluster_and_plot_scatter(df, bands, clusters, x, y, color, continuous, hover_name, labels,
                                              title=f'{clusters} clusters',
                                              log_y=log_y, height=height, marker_size=marker_size)


            for t in subfig.data: fig.add_trace(t, row=row+1, col=col+1)

            fig.update_yaxes(title_text=y, type='log' if log_y else None, row=row+1, col=col+1)
            fig.update_xaxes(title_text=x, type='log' if log_x else None, row=row+1, col=col+1)

    fig.update_layout(showlegend=False, height=height*rows)

    return fig


# Cell
def PCA_decomposition(df, calc_bands, inf_bands=None, n_components=2):
    "Applies PCA decomposition in Dataframe df, using the bands specified in calc_bands.\nInf_bands will be returned. If None is specified, the full dataframe with PCA columns will be returned"

    xtrain = df[calc_bands].to_numpy()

    pca = decomposition.PCA(n_components=n_components)
    pca_modes = pca.fit_transform(xtrain)


    if inf_bands is None: inf_bands = df.columns
    pca_df = pd.concat([df[inf_bands].reset_index(drop=True),
                        pd.DataFrame(pca_modes, columns=[f'PCA{i}' for i in range(1, n_components+1)])],
                       axis=1)

    return pca_df


def clusterize(df, columns, inf_columns=None, n_clusters=2, cluster_column='cluster', norm=None, weights=None):
    """
    Given a dataframe, do the clustering using the given columns  and save the cluster number
    in a new column (cluster_column).
    :param df: Datafame with the features
    :param columns: The columns that will be used to do the clustering procedure.
    :param inf_columns: The columns to be kept in the resulting dataframe
    :param n_clusters: Number of clusters
    :param cluster_column: The name of the column with the clustering result
    :param norm: The normalization method: None, 'Standard', 'MinMax', 'Robust', 'Normalizer', 'Power'
    :param weights: Weights to be applied to each features after normalization. If None, no weights are applied
    :return: Dataframe with a new column indicating the cluster number.
    """

    x_train = df[columns].to_numpy()

    Scaler = None
    if norm:
        if norm == 'Standard':
            from sklearn.preprocessing import StandardScaler as Scaler
        elif norm == 'MinMax':
            from sklearn.preprocessing import MinMaxScaler as Scaler
        elif norm == 'Robust':
            from sklearn.preprocessing import RobustScaler as Scaler
        elif norm == 'Normalizer':
            from sklearn.preprocessing import Normalizer as Scaler
        elif norm == 'Power':
            from sklearn.preprocessing import PowerTransformer as Scaler
        else:
            print(f'Normalization method {norm} not supported')

        x_train = Scaler().fit_transform(x_train)

        if weights:
            x_train = x_train * np.array(weights)[None, ...]

    clustering = cluster.AgglomerativeClustering(n_clusters=n_clusters)
    clustering.fit(x_train)

    inf_columns = df.columns if inf_columns is None else listify(inf_columns)

    if cluster_column in inf_columns:
        inf_columns = inf_columns.drop(cluster_column)

    cluster_df = pd.concat([df[inf_columns],
                            pd.DataFrame(clustering.labels_, index=df.index, columns=[cluster_column])],
                           axis=1)

    return cluster_df


# def nir_red_ratio(x, a, b):
#     return a * np.power(x, b)
#
# def linear(x, a, b):
#     return a*x+b
#
# def expo(x, a, b):
#     return a*10**x+b
#
# def power(x, a, b):
# #     pdb.set_trace()
#     return a*(x)**(b)
#
# def poly(x, a, b, c, d):
#     return a*x**b+c*x+d
#
# def nechad(red, a=610.94, c=0.2324):
#     return a * red / (1 - (red / c))


# functions to fet a generic function into a set of data
# def fit_curve(func, X, y):
#     popt, pcov = curve_fit(func, X, y, check_finite=False)
#     r2, rmse, SSE = calc_errors(X, y, func, popt)
#
#     return popt, r2, rmse, SSE
#
# def calc_errors(X, y, func, params=[], decimal=2):
#
#     y_hat = func(X, *params)
#     r2 = round(r2_score(y, y_hat), decimal)
#     rmse = round(math.sqrt(mean_squared_error(y, y_hat)), decimal)
#
#     SSE = round(((y-y_hat)**2).sum(), decimal)
#
#     return r2, rmse, SSE
def plot_data_and_curve(df, X, y, color, hover_name, hover_data, xlabel, func, params=[], title="", height=600):

    x = X if X.ndim == 1 else X.iloc[:,0]

    fig = px.scatter(df[['SPM', 'Id', 'Rio/ Bacia', 'cluster']], x=x, y=y,
                 color=color, height=height, hover_name=hover_name,
                 hover_data=hover_data, labels={'x': xlabel})

    if (X.ndim == 1):
        xs = np.linspace(np.min(X)*0.8, np.max(X)*1.05, 100000)
        spm = func(xs, *params)
        fig.add_trace(go.Scatter(x=xs, y=spm, mode='lines'))
    else:
        for bright in [0.02, 0.03, 0.04, 0.05]:
            xs = np.linspace(np.min(x)*0.8, np.max(x)*1.05, 100)
            xs = np.concatenate((xs[..., None], np.repeat(bright, 100, axis=0)[..., None]), axis=1)
    #         pdb.set_trace()

            spm = func(xs, *params)
            fig.add_trace(go.Scatter(x=xs[:, 0], y=spm, mode='lines'))

    if title == '':
        r2, rmse, SSE = calc_errors(X, y, func, params)
        title = f'Function {func.__name__}  -  R^2 = {r2}  rmse = {rmse}  SSE = {SSE}'

    fig.update_layout(title=title)
#     fig.update_layout(yaxis_type='log')

    return fig


def fit_and_plot_curve(df, X, y, color, hover_name, hover_data, xlabel, func, height=600):

    params, r2, rmse , SSE = fit_curve(func, X, y)

    title=f'Function {func.__name__}  -  R^2 = {r2}  rmse = {rmse}  SSE = {SSE}'

    print(title)

    return plot_data_and_curve(df, X, y, color, hover_name, hover_data, xlabel, func, params, title)